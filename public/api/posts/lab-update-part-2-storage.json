{
  "slug": "lab-update-part-2-storage",
  "title": "Lab Update ‚Äì Part 2 Storage Truenas Scale",
  "description": "Synology to TrueNas storage move and increase in performance",
  "date": "2022-01-11T22:35:02Z",
  "modified": "2023-12-11T15:02:10Z",
  "author": "James Kilby",
  "url": "https://jameskilby.co.uk/2022/01/lab-update-part-2-storage/",
  "markdown_url": "/markdown/posts/lab-update-part-2-storage.md",
  "api_url": "/api/posts/lab-update-part-2-storage.json",
  "categories": [
    "Homelab",
    "Storage",
    "Networking",
    "VMware",
    "Artificial Intelligence",
    "Ansible",
    "vSphere",
    "Nutanix"
  ],
  "tags": [
    null,
    null,
    null,
    null
  ],
  "image": "https://jameskilby.co.uk/wp-content/uploads/2022/01/maxresdefault.jpeg",
  "content": "![](https://jameskilby.co.uk/wp-content/uploads/2022/01/maxresdefault.jpeg)\n\n[Homelab](https://jameskilby.co.uk/category/homelab/) | [Storage](https://jameskilby.co.uk/category/storage/)\n\n# Lab Update ‚Äì Part 2 Storage Truenas Scale\n\nBy[James](https://jameskilby.co.uk) January 11, 2022December 11, 2023 ‚Ä¢ üìñ2 min read(495 words)\n\nüìÖ **Published:** January 11, 2022‚Ä¢ **Updated:** December 11, 2023\n\nThe HP Z840 has changed its role to a permanent storage box running Truenas Scale. This is in addition to my Synology DS918+\n\nTrueNas is the successor to FreeNas a very popular BSD based StorageOS and TrueNas scale is a fork of this based on Linux.\n\nThe Synology has been an amazing piece of kit handling VM storage, Docker, File sharing and Plex duties. It will maintain most of these roles. However, I needed something faster for my lab and especially something with faster network access. The Synology I had was limited to 2xGb interfaces. An option was to buy a newer Synology but I felt a better route was to try a ‚ÄúStorage OS‚Äù on some of my existing hardware with some network tweaks to be seen later.\n\nThe Spec of the Z840 Workstation I am using to run Truenas is 2x Intel Xeon CPU E5-2673 v3 @ 2.40GHz and 128GB of RAM. More than enough for my needs. I will use the 2xGb interfaces for management and the new network for a combination of iSCSI/NFS\n\nWithin one of the 5 1/2 inch drive bays I have placed an Icy Dock express cage giving me 6 additional 2.5 drive bays.\n\n![](https://jameskilby.co.uk/wp-content/uploads/2023/04/iu-1.jpeg)ICY Dock\n\nI have placed the TrueNAS OS on 2x Intel 80GB SSD‚Äôs running within these.\n\nFor now, I have configured 2 storage pools. One NVMe with a single INTEL SSDPE2MX020T7. This will be very high-performance storage but for now, is not redundant. I plan to mitigate this with regular backups.\n\nThe other is reusing some 3TB WD Red drives from the Synology in a Raid-Z config. I will likely add some SSD as a ZLOG at a later date.\n\nThis is presented back to my VMware hosts using iSCSI over a 25Gb direct network. I have only done basic testing so far. John would murder me for this but I did a test using CrystalDisk just to check everything was in the correct realms of what I would expect. (These numbers will have been influenced by cache size as they easily fit in the working set)\n\nI chose to use the real-world test built into Crystel Disk Mark. I‚Äôm sure the numbers would be much higher with other configs. This was also done with a 4GiB file which isn‚Äôt huge but I used to keep the testing short. I will come back and test the storage properly at a later date.\n\n![](https://jameskilby.co.uk/wp-content/uploads/2022/01/Screenshot-2022-01-17-at-09.11.14.png)\n\nNVMe initial performance test. I had a number of VM‚Äôs running on the NVMe test at the time testing was running. This may account for the read being slightly lower than the SATA disks but the Write performance is much higher.\n\n![](https://jameskilby.co.uk/wp-content/uploads/2022/01/NVMe.png)\n\nTrueNAS SATA test. 3x Sata disks in Raid5 \n\n![](https://jameskilby.co.uk/wp-content/uploads/2022/01/Screenshot-2022-01-17-at-09.07.00.png)\n\nComparison with Synology 3x SSD Raid 5 ( 2x1Gb/s ) Networking. You can see this is significantly lower than the Freenas box. The Synology was running a number of docker containers and apps at the time so I‚Äôm sure performance could be higher.\n\n![](https://jameskilby.co.uk/wp-content/uploads/2022/01/Synology-1024x725.png)\n\n## Similar Posts\n\n  * [ ![100Gb/s in my Homelab](https://jameskilby.co.uk/wp-content/uploads/2023/04/2157_hi_res-768x346.png) ](https://jameskilby.co.uk/2022/12/100gb-s-in-my-homelab-sort-of/)\n\n[Homelab](https://jameskilby.co.uk/category/homelab/) | [Networking](https://jameskilby.co.uk/category/networking/) | [Storage](https://jameskilby.co.uk/category/storage/) | [VMware](https://jameskilby.co.uk/category/vmware/)\n\n### [100Gb/s in my Homelab](https://jameskilby.co.uk/2022/12/100gb-s-in-my-homelab-sort-of/)\n\nBy[James](https://jameskilby.co.uk) December 19, 2022November 11, 2023\n\nFor a while, I‚Äôve been looking to update the networking at the core of my homelab. I have had some great results with the current setup utilising a number of DAC‚Äôs but there were a couple of things that were annoying me. Then MikroTik dropped the CRS504-4XQ-IN and if the price wasn‚Äôt horrendous then that‚Ä¶\n\n  * [ ![Nvidia Tesla P4 Homelab Setup](https://jameskilby.co.uk/wp-content/uploads/2023/10/IMG_1107-768x403-1.jpg) ](https://jameskilby.co.uk/2023/10/vgpu-setup-in-my-homelab/)\n\n[Homelab](https://jameskilby.co.uk/category/homelab/) | [VMware](https://jameskilby.co.uk/category/vmware/)\n\n### [Nvidia Tesla P4 Homelab Setup](https://jameskilby.co.uk/2023/10/vgpu-setup-in-my-homelab/)\n\nBy[James](https://jameskilby.co.uk) October 23, 2023July 10, 2024\n\nA little while ago I decided to play with vGPU in my homelab. This was something I had dabbled with in the past but never really had the time or need to get working properly. The first thing that I needed was a GPU. I did have a Dell T20 with an iGPU built into‚Ä¶\n\n  * [ ![Wa](https://jameskilby.co.uk/wp-content/uploads/2025/04/210902461-012e7273-413a-4ec7-be44-e854347f5a21-768x180.png) ](https://jameskilby.co.uk/2025/04/warp-the-intelligent-terminal/)\n\n[Artificial Intelligence](https://jameskilby.co.uk/category/artificial-intelligence/) | [Homelab](https://jameskilby.co.uk/category/homelab/)\n\n### [Warp ‚Äì The intelligent terminal](https://jameskilby.co.uk/2025/04/warp-the-intelligent-terminal/)\n\nBy[James](https://jameskilby.co.uk) April 11, 2025October 3, 2025\n\nHow Warp is helping me run my homelab. \n\n  * [ ![Managing my Homelab with SemaphoreUI](https://jameskilby.co.uk/wp-content/uploads/2025/07/semaphore-768x768.png) ](https://jameskilby.co.uk/2025/09/managing-my-homelab-with-semaphoreui/)\n\n[Ansible](https://jameskilby.co.uk/category/ansible/) | [Homelab](https://jameskilby.co.uk/category/homelab/)\n\n### [Managing my Homelab with SemaphoreUI](https://jameskilby.co.uk/2025/09/managing-my-homelab-with-semaphoreui/)\n\nBy[James](https://jameskilby.co.uk) September 2, 2025December 18, 2025\n\nI recently stumbled across Semaphore, which is essentially a frontend for managing DevOps tooling, including Ansible, Terraform, OpenTofu, and PowerShell. It‚Äôs easy to deploy in Docker, and I am slowly moving more of my homelab management over to it. Introduction This is a guide to show you how to get up and running easily with‚Ä¶\n\n  * [ ![Forcing an Upgrade to vSphere 8](https://jameskilby.co.uk/wp-content/uploads/2022/12/Screenshot-2022-12-14-at-21.45.23.png) ](https://jameskilby.co.uk/2022/12/forcing-an-upgrade-to-vsphere-8/)\n\n[Homelab](https://jameskilby.co.uk/category/homelab/) | [VMware](https://jameskilby.co.uk/category/vmware/) | [vSphere](https://jameskilby.co.uk/category/vsphere/)\n\n### [Forcing an Upgrade to vSphere 8](https://jameskilby.co.uk/2022/12/forcing-an-upgrade-to-vsphere-8/)\n\nBy[James](https://jameskilby.co.uk) December 14, 2022October 1, 2025\n\nI run a reasonably extensive homelab that is of course built around the VMware ecosystem. So with the release of vSphere 8 I was obviously going to upgrade however a few personal things blocked me from doing it until now. The vCenter upgrade was smooth however knowing that some of the hardware I am running‚Ä¶\n\n  * [ ![Nutanix CE](https://jameskilby.co.uk/wp-content/uploads/2020/07/nutanix-logo-HI-REZ_reverse-w-carrier-768x196.jpg) ](https://jameskilby.co.uk/2018/01/nutanix-ce/)\n\n[Homelab](https://jameskilby.co.uk/category/homelab/) | [Nutanix](https://jameskilby.co.uk/category/nutanix/)\n\n### [Nutanix CE](https://jameskilby.co.uk/2018/01/nutanix-ce/)\n\nBy[James](https://jameskilby.co.uk) January 6, 2018July 10, 2024\n\nI ran a Nutanix CE server at home for a little while when it first came out. However, due to the fairly high requirements, it didn‚Äôt make sense to me to continue running it at home. This was compounded by the fact that I have many clusters to play with at work. These all run my‚Ä¶",
  "excerpt": "![](https://jameskilby.co.uk/wp-content/uploads/2022/01/maxresdefault.jpeg)\n\n[Homelab](https://jameskilby.co.uk/category/homelab/) | [Storage](https://jameskilby.co.uk/category/storage/)\n\n# Lab Update ‚Äì Part 2 Storage Truenas Scale\n\nBy[James](https://jameskilby.co.uk) January 11, 2022December 11, 20..."
}