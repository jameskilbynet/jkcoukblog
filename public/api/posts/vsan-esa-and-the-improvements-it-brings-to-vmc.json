{
  "slug": "vsan-esa-and-the-improvements-it-brings-to-vmc",
  "title": "VMC ‚Äì vSAN ESA",
  "description": "The benefits of vSAN ESA in VMware Cloud on AWS",
  "date": "2023-11-17T11:29:42Z",
  "modified": "2024-07-10T10:40:28Z",
  "author": "James Kilby",
  "url": "https://jameskilby.co.uk/2023/11/vsan-esa-and-the-improvements-it-brings-to-vmc/",
  "markdown_url": "/markdown/posts/vsan-esa-and-the-improvements-it-brings-to-vmc.md",
  "api_url": "/api/posts/vsan-esa-and-the-improvements-it-brings-to-vmc.json",
  "categories": [
    "VMware",
    "VMware Cloud on AWS",
    "vSAN",
    "VCF",
    "Personal",
    "Homelab",
    "Veeam",
    "vSphere",
    "AWS"
  ],
  "tags": [
    null,
    null,
    null,
    null
  ],
  "image": "https://jameskilby.co.uk/wp-content/uploads/2023/11/OrigionalPoweredByvSAN-550x324-1.jpg",
  "content": "![](https://jameskilby.co.uk/wp-content/uploads/2023/11/OrigionalPoweredByvSAN-550x324-1.jpg)\n\n[VMware](https://jameskilby.co.uk/category/vmware/) | [VMware Cloud on AWS](https://jameskilby.co.uk/category/vmware/vmware-cloud-on-aws/) | [vSAN](https://jameskilby.co.uk/category/vmware/vsan-vmware/)\n\n# VMC ‚Äì vSAN ESA\n\nBy[James](https://jameskilby.co.uk) November 17, 2023July 10, 2024 ‚Ä¢ üìñ4 min read(851 words)\n\nüìÖ **Published:** November 17, 2023‚Ä¢ **Updated:** July 10, 2024\n\n## Table of Contents\n\nvSAN Express Storage Architecture (ESA) was announced at VMware Explore last year (2022) and while it‚Äôs been available for our on-premise customers for nearly a year it hasn‚Äôt been available in VMC until now‚Ä¶. With the release of the M24 version of VMC. It is now an option for newly provisioned SDDC‚Äôs\n\nSo why is this such an important change? to answer that we need a history lesson on vSAN\n\n![](https://jameskilby.co.uk/wp-content/uploads/2023/10/Introducing-ESA-Figure01-1024x422.png)\n\nvSAN first came to market in 2014, and the typical hardware of the day from a storage perspective was dominated by spindles. Flash had arrived on the scene but was VERY expensive and datacenter networking was in the transition from 1Gb/s to 10Gb/s. As a result of this and other factors design decisions were made in the original vSAN (referred to here as OSA) to implement a tiered storage architecture. This was made up of flash-based cache drives and flash or hard disk-based capacity drives. These were then combined into something called a disk group. This decision led to several consequences.\n\nThe first is that the cache drive cannot be used for storing data it is only a transient write buffer. As all writes go to the cache drive in a disk group in some circumstances this could limit the peak I/O available. \n\nIt also meant that the endurance of this drive was paramount. This was a challenge in the early days of flash drives. \n\nTo improve performance and reduce failure domains it‚Äôs possible to have multiple disk groups within a host. This is something that we implement in VMC using vSAN OSA this further compounds the reduction in usable storage. as multiple drives are allocated to the cache role.\n\nAs All-Flash has now become the normality it was worth revisiting the architecture. \n\nTo understand more about the under-the-hood architecture of vSAN see the [official overview ](https://core.vmware.com/blog/introduction-vsan-express-storage-architecture)\n\n## vSAN ESA ‚Äì Benefits\n\nPutting all of the above changes together brings significant benefits to VMC customers when using the ESA version of vSAN.\n\n### Performance benefits\n\n  * Significant increase in available IOPS ( all drives are used for reading and writing)\n  * Adaptive write path for maximum throughput (Especially relevant for customers that require high throughput on a single or low number of VMDK‚Äôs) \n  * Improved snapshot mechanisms reduce the impact on the guest workload (Snapshot deletion is up to 100x faster combined with much reduced primary latency when running workloads from snapshots. As business demands lower RPO‚Äôs any improvement in snapshot mechanisms reduce the overhead to the guest workload.\n\n### Efficiency benefits \n\n  * Improved compression algorithms for better data reduction\n  * More efficient compression algorithms free up the Host CPU for Guest OS processing\n  * Reduced storage network traffic (compression happens on the source host and then all replication is already compressed)\n  * further enhancements reduce the CPU overhead when using vSAN Encryption (This is always used in VMC)\n  * Always on [UNMAP/Trim](https://www.techtarget.com/searchstorage/definition/TRIM) (This helps to free up unused blocks at the Nand block level) \n  * The ability to deploy a parity-based (RAID5) with 3 Nodes. (OSA requires a minimum of 4)\n  * The performance of the parity-based (RAID5/6) of the ESA implementation now exceeds the RAID1 performance of OSA. Customers can get increase savings by changing the storage policy.\n\n### Resilience Benefits\n\n  * less rewrites in the event of a device replacement ‚Äì Although this is a significant benefit for on-premise customers with VMC if we have a drive failure we will replace the entire node. \n\nvSAN will only be available on the i4.metal-based VMC hosts at launch. It is also not currently available in a 2-node or Stretched SDDC configuration\n\n## Sizing\n\nAs part of my job in VMware Cloud Pre-Sales a critical aspect is sizing VMC solutions for customers. This is usually done as a first pass with [RVtools](https://www.robware.net/rvtools/) inputs into our sizing tools. \n\nBut what does that mean to a customer?\n\nMy colleague [Nikolay](https://nkulikov.com) put together this handy table. This is assuming a conservative compression ratio of 1.25% for ESA. The reality is we expect this to be higher.\n\n**Nodes**|  **OSA (Compression 1.25)  \nPolicy In use**|  **Capacity (TiB)**|  **ESA  \n(Compression 1.25)  \nPolicy In use**|  **Capacity (TiB)**|  **Delta %**  \n---|---|---|---|---|---  \n2| FTT1, Mirror| 14.09| N/A| N/A| N/A  \n3| FTT1, Mirror| 23.5| FTT1, RAID5| 37.22| 58.38  \n4| FTT1, RAID5| 51.87| FTT1, RAID5| 51.21| -1.27*  \n5| FTT1, RAID5| 66.03| FTT1, RAID5| 65.19| -1.27*  \n6| FTT2, RAID6| 70.56| FTT2, RAID6| 79.18| 12.22  \n7| FTT2, RAID6| 83.11| FTT2, RAID6| 93.16| 12.09  \n8| FTT2, RAID6| 95.65| FTT2, RAID6| 107.15| 12.02  \n9| FTT2, RAID6| 108.2| FTT2, RAID6| 121.13| 11.95  \n10| FTT2, RAID6| 120.75| FTT2, RAID6| 135.12| 11.90  \n11| FTT2, RAID6| 133.3| FTT2, RAID6| 149.1| 11.85  \n12| FTT2, RAID6| 145.85| FTT2, RAID6| 163.09| 11.82  \n13| FTT2, RAID6| 158.4| FTT2, RAID6| 177.08| 11.79  \n14| FTT2, RAID6| 170.95| FTT2, RAID6| 191.06| 11.76  \n15| FTT2, RAID6| 183.5| FTT2, RAID6| 205.05| 11.74  \n16| FTT2, RAID6| 196.04| FTT2, RAID6| 219.03| 11.73  \n  \n*As ESA has a dynamic parity-based mechanism it can either use 2+1 or 4+1 however OSA has the capability of using 3+1. This is why the 4 and 5 node has a lower usable space. \n\nThe above table is the usable capacity for workloads including the management objects. Additional clusters would have more space.\n\n## üìö Related Posts\n\n  * [Using Content Libraries in VMC to deploy software faster](https://jameskilby.co.uk/2026/01/using-content-libraries-in-vmc-to-deploy-software-faster/)\n  * [vSAN Cluster Shutdown &#8211; Orchestration](https://jameskilby.co.uk/2025/12/vsan-cluster-shutdown/)\n  * [An in-depth look at VMware Cloud on AWS hosts](https://jameskilby.co.uk/2025/08/vmc-host-deepdive/)\n\n## Similar Posts\n\n  * [ ![Holodeck CPU Fixes](https://jameskilby.co.uk/wp-content/uploads/2024/01/40oOd8IipPvtrPJs-1198788743-768x737.jpg) ](https://jameskilby.co.uk/2024/01/holodeck-cpu-fixes/)\n\n[VCF](https://jameskilby.co.uk/category/vmware/vcf/) | [VMware](https://jameskilby.co.uk/category/vmware/)\n\n### [Holodeck CPU Fixes](https://jameskilby.co.uk/2024/01/holodeck-cpu-fixes/)\n\nBy[James](https://jameskilby.co.uk) January 18, 2024July 10, 2024\n\nHow to deploy Holodeck with Legacy CPU‚Äôs\n\n  * [ ![VMware Certified Master Specialist HCI 2020](https://jameskilby.co.uk/wp-content/uploads/2020/09/vmware_SP_HCI20.png) ](https://jameskilby.co.uk/2020/09/vmware-certified-master-specialist-hci-2020/)\n\n[Personal](https://jameskilby.co.uk/category/personal/) | [VMware](https://jameskilby.co.uk/category/vmware/)\n\n### [VMware Certified Master Specialist HCI 2020](https://jameskilby.co.uk/2020/09/vmware-certified-master-specialist-hci-2020/)\n\nBy[James](https://jameskilby.co.uk) September 13, 2020November 11, 2023\n\nI recently sat (and passed the VMware HCI Master Specialist exam (5V0-21.20). I won‚Äôt go into any details of the contents but I will comment that I felt the questions were fair and that there wasn‚Äôt anything in it to trip you up. The required knowledge was certainly wider than the vSAN specialist exam. This‚Ä¶\n\n  * [Homelab](https://jameskilby.co.uk/category/homelab/) | [Veeam](https://jameskilby.co.uk/category/veeam/) | [VMware](https://jameskilby.co.uk/category/vmware/)\n\n### [Lab Update ‚Äì Desired Workloads](https://jameskilby.co.uk/2022/01/lab-update-part-5-desired-workloads/)\n\nBy[James](https://jameskilby.co.uk) January 6, 2022November 11, 2023\n\nMy lab is always undergoing change. Partially as I want to try new things or new ways of doing things. Sometimes because I break things (not always by accident) sometimes it‚Äôs a great way to learn‚Ä¶. I decided to list the workloads I am looking to run (some of these are already in place) Infrastucture‚Ä¶\n\n  * [ ![Forcing an Upgrade to vSphere 8](https://jameskilby.co.uk/wp-content/uploads/2022/12/Screenshot-2022-12-14-at-21.45.23.png) ](https://jameskilby.co.uk/2022/12/forcing-an-upgrade-to-vsphere-8/)\n\n[Homelab](https://jameskilby.co.uk/category/homelab/) | [VMware](https://jameskilby.co.uk/category/vmware/) | [vSphere](https://jameskilby.co.uk/category/vsphere/)\n\n### [Forcing an Upgrade to vSphere 8](https://jameskilby.co.uk/2022/12/forcing-an-upgrade-to-vsphere-8/)\n\nBy[James](https://jameskilby.co.uk) December 14, 2022October 1, 2025\n\nI run a reasonably extensive homelab that is of course built around the VMware ecosystem. So with the release of vSphere 8 I was obviously going to upgrade however a few personal things blocked me from doing it until now. The vCenter upgrade was smooth however knowing that some of the hardware I am running‚Ä¶\n\n  * [VMware](https://jameskilby.co.uk/category/vmware/) | [AWS](https://jameskilby.co.uk/category/aws/) | [Veeam](https://jameskilby.co.uk/category/veeam/)\n\n### [Monitoring VMC ‚Äì Part 1](https://jameskilby.co.uk/2019/12/monitoring-vmc-part-1/)\n\nBy[James](https://jameskilby.co.uk) December 17, 2019October 1, 2025\n\nAs previously mentioned I have been working a lot with VMware Cloud on AWS and one of the questions that often crops up is around an approach to monitoring. This is an interesting topic as VMC is technically ‚Äúas a service‚Äù therefore the monitoring approach is a bit different. Technically AWS and VMware‚Äôs SRE teams‚Ä¶\n\n  * [ ![An in-depth look at VMware Cloud on AWS hosts](https://jameskilby.co.uk/wp-content/uploads/2025/02/Picture-1-e1768509620339-768x193.png) ](https://jameskilby.co.uk/2025/08/vmc-host-deepdive/)\n\n[VMware](https://jameskilby.co.uk/category/vmware/) | [VMware Cloud on AWS](https://jameskilby.co.uk/category/vmware/vmware-cloud-on-aws/)\n\n### [An in-depth look at VMware Cloud on AWS hosts](https://jameskilby.co.uk/2025/08/vmc-host-deepdive/)\n\nBy[James](https://jameskilby.co.uk) August 14, 2025January 18, 2026\n\nThis is single page intended to collate every single feature of the current VMware Cloud on AWS hosts for easy comparison. All of this data Is publicly available. I have just collated into a single page I3 I3en I4i CPU Processor Name Intel Xeon E5-2686 v4 Intel Xeon Platinum 8175 Intel Xeon 8375c No of‚Ä¶",
  "excerpt": "![](https://jameskilby.co.uk/wp-content/uploads/2023/11/OrigionalPoweredByvSAN-550x324-1.jpg)\n\n[VMware](https://jameskilby.co.uk/category/vmware/) | [VMware Cloud on AWS](https://jameskilby.co.uk/category/vmware/vmware-cloud-on-aws/) | [vSAN](https://jameskilby.co.uk/category/vmware/vsan-vmware/)\n\n#..."
}