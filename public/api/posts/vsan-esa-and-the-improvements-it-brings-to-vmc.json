{
  "slug": "vsan-esa-and-the-improvements-it-brings-to-vmc",
  "title": "VMC â€“ vSAN ESA",
  "description": "The benefits of vSAN ESA in VMware Cloud on AWS",
  "date": "2023-11-17T11:29:42Z",
  "modified": "2024-07-10T10:40:28Z",
  "author": "James Kilby",
  "url": "https://jameskilby.co.uk/2023/11/vsan-esa-and-the-improvements-it-brings-to-vmc/",
  "markdown_url": "/markdown/posts/vsan-esa-and-the-improvements-it-brings-to-vmc.md",
  "api_url": "/api/posts/vsan-esa-and-the-improvements-it-brings-to-vmc.json",
  "categories": [
    "VMware",
    "VMware Cloud on AWS",
    "vSAN",
    "VCF",
    "Homelab",
    "Storage",
    "Synology",
    "Veeam"
  ],
  "tags": [
    null,
    null,
    null,
    null
  ],
  "image": "https://jameskilby.co.uk/wp-content/uploads/2023/11/OrigionalPoweredByvSAN-550x324-1.jpg",
  "content": "![](https://jameskilby.co.uk/wp-content/uploads/2023/11/OrigionalPoweredByvSAN-550x324-1.jpg)\n\n[VMware](https://jameskilby.co.uk/category/vmware/) | [VMware Cloud on AWS](https://jameskilby.co.uk/category/vmware/vmware-cloud-on-aws/) | [vSAN](https://jameskilby.co.uk/category/vmware/vsan-vmware/)\n\n# VMC â€“ vSAN ESA\n\nBy[James](https://jameskilby.co.uk) November 17, 2023July 10, 2024 â€¢ ðŸ“–4 min read(851 words)\n\nðŸ“… **Published:** November 17, 2023â€¢ **Updated:** July 10, 2024\n\n## Table of Contents\n\nvSAN Express Storage Architecture (ESA) was announced at VMware Explore last year (2022) and while itâ€™s been available for our on-premise customers for nearly a year it hasnâ€™t been available in VMC until nowâ€¦. With the release of the M24 version of VMC. It is now an option for newly provisioned SDDCâ€™s\n\nSo why is this such an important change? to answer that we need a history lesson on vSAN\n\n![](https://jameskilby.co.uk/wp-content/uploads/2023/10/Introducing-ESA-Figure01-1024x422.png)\n\nvSAN first came to market in 2014, and the typical hardware of the day from a storage perspective was dominated by spindles. Flash had arrived on the scene but was VERY expensive and datacenter networking was in the transition from 1Gb/s to 10Gb/s. As a result of this and other factors design decisions were made in the original vSAN (referred to here as OSA) to implement a tiered storage architecture. This was made up of flash-based cache drives and flash or hard disk-based capacity drives. These were then combined into something called a disk group. This decision led to several consequences.\n\nThe first is that the cache drive cannot be used for storing data it is only a transient write buffer. As all writes go to the cache drive in a disk group in some circumstances this could limit the peak I/O available. \n\nIt also meant that the endurance of this drive was paramount. This was a challenge in the early days of flash drives. \n\nTo improve performance and reduce failure domains itâ€™s possible to have multiple disk groups within a host. This is something that we implement in VMC using vSAN OSA this further compounds the reduction in usable storage. as multiple drives are allocated to the cache role.\n\nAs All-Flash has now become the normality it was worth revisiting the architecture. \n\nTo understand more about the under-the-hood architecture of vSAN see the [official overview ](https://core.vmware.com/blog/introduction-vsan-express-storage-architecture)\n\n## vSAN ESA â€“ Benefits\n\nPutting all of the above changes together brings significant benefits to VMC customers when using the ESA version of vSAN.\n\n### Performance benefits\n\n  * Significant increase in available IOPS ( all drives are used for reading and writing)\n  * Adaptive write path for maximum throughput (Especially relevant for customers that require high throughput on a single or low number of VMDKâ€™s) \n  * Improved snapshot mechanisms reduce the impact on the guest workload (Snapshot deletion is up to 100x faster combined with much reduced primary latency when running workloads from snapshots. As business demands lower RPOâ€™s any improvement in snapshot mechanisms reduce the overhead to the guest workload.\n\n### Efficiency benefits \n\n  * Improved compression algorithms for better data reduction\n  * More efficient compression algorithms free up the Host CPU for Guest OS processing\n  * Reduced storage network traffic (compression happens on the source host and then all replication is already compressed)\n  * further enhancements reduce the CPU overhead when using vSAN Encryption (This is always used in VMC)\n  * Always on [UNMAP/Trim](https://www.techtarget.com/searchstorage/definition/TRIM) (This helps to free up unused blocks at the Nand block level) \n  * The ability to deploy a parity-based (RAID5) with 3 Nodes. (OSA requires a minimum of 4)\n  * The performance of the parity-based (RAID5/6) of the ESA implementation now exceeds the RAID1 performance of OSA. Customers can get increase savings by changing the storage policy.\n\n### Resilience Benefits\n\n  * less rewrites in the event of a device replacement â€“ Although this is a significant benefit for on-premise customers with VMC if we have a drive failure we will replace the entire node. \n\nvSAN will only be available on the i4.metal-based VMC hosts at launch. It is also not currently available in a 2-node or Stretched SDDC configuration\n\n## Sizing\n\nAs part of my job in VMware Cloud Pre-Sales a critical aspect is sizing VMC solutions for customers. This is usually done as a first pass with [RVtools](https://www.robware.net/rvtools/) inputs into our sizing tools. \n\nBut what does that mean to a customer?\n\nMy colleague [Nikolay](https://nkulikov.com) put together this handy table. This is assuming a conservative compression ratio of 1.25% for ESA. The reality is we expect this to be higher.\n\n**Nodes**|  **OSA (Compression 1.25)  \nPolicy In use**|  **Capacity (TiB)**|  **ESA  \n(Compression 1.25)  \nPolicy In use**|  **Capacity (TiB)**|  **Delta %**  \n---|---|---|---|---|---  \n2| FTT1, Mirror| 14.09| N/A| N/A| N/A  \n3| FTT1, Mirror| 23.5| FTT1, RAID5| 37.22| 58.38  \n4| FTT1, RAID5| 51.87| FTT1, RAID5| 51.21| -1.27*  \n5| FTT1, RAID5| 66.03| FTT1, RAID5| 65.19| -1.27*  \n6| FTT2, RAID6| 70.56| FTT2, RAID6| 79.18| 12.22  \n7| FTT2, RAID6| 83.11| FTT2, RAID6| 93.16| 12.09  \n8| FTT2, RAID6| 95.65| FTT2, RAID6| 107.15| 12.02  \n9| FTT2, RAID6| 108.2| FTT2, RAID6| 121.13| 11.95  \n10| FTT2, RAID6| 120.75| FTT2, RAID6| 135.12| 11.90  \n11| FTT2, RAID6| 133.3| FTT2, RAID6| 149.1| 11.85  \n12| FTT2, RAID6| 145.85| FTT2, RAID6| 163.09| 11.82  \n13| FTT2, RAID6| 158.4| FTT2, RAID6| 177.08| 11.79  \n14| FTT2, RAID6| 170.95| FTT2, RAID6| 191.06| 11.76  \n15| FTT2, RAID6| 183.5| FTT2, RAID6| 205.05| 11.74  \n16| FTT2, RAID6| 196.04| FTT2, RAID6| 219.03| 11.73  \n  \n*As ESA has a dynamic parity-based mechanism it can either use 2+1 or 4+1 however OSA has the capability of using 3+1. This is why the 4 and 5 node has a lower usable space. \n\nThe above table is the usable capacity for workloads including the management objects. Additional clusters would have more space.\n\n## Similar Posts\n\n  * [ ![Holodeck CPU Fixes](https://jameskilby.co.uk/wp-content/uploads/2024/01/40oOd8IipPvtrPJs-1198788743-768x737.jpg) ](https://jameskilby.co.uk/2024/01/holodeck-cpu-fixes/)\n\n[VCF](https://jameskilby.co.uk/category/vmware/vcf/) | [VMware](https://jameskilby.co.uk/category/vmware/)\n\n### [Holodeck CPU Fixes](https://jameskilby.co.uk/2024/01/holodeck-cpu-fixes/)\n\nBy[James](https://jameskilby.co.uk) January 18, 2024July 10, 2024\n\nHow to deploy Holodeck with Legacy CPUâ€™s\n\n  * [ ![Homelab bad days \\(almost\\)](https://jameskilby.co.uk/wp-content/uploads/2022/11/BrokenHardDive-1200x630-1-768x403.jpg) ](https://jameskilby.co.uk/2022/11/homelab-bad-days-almost/)\n\n[Homelab](https://jameskilby.co.uk/category/homelab/) | [Storage](https://jameskilby.co.uk/category/storage/) | [Synology](https://jameskilby.co.uk/category/synology/)\n\n### [Homelab bad days (almost)](https://jameskilby.co.uk/2022/11/homelab-bad-days-almost/)\n\nBy[James](https://jameskilby.co.uk) November 21, 2022April 8, 2023\n\nI recently spent 3 weeks in Ireland with my wife Wendy and our son Nate. This involves driving from the south coast of Dorset up to Scotland and then getting a ferry over to Belfast before travelling west to the Republic. While driving I got a slack notification that one of my SSDâ€™s in myâ€¦\n\n  * [Homelab](https://jameskilby.co.uk/category/homelab/) | [Storage](https://jameskilby.co.uk/category/storage/) | [Synology](https://jameskilby.co.uk/category/synology/)\n\n### [Lab Storage](https://jameskilby.co.uk/2018/01/lab-storage/)\n\nBy[James](https://jameskilby.co.uk) January 6, 2018July 10, 2024\n\nI have been meaning to post around some of the lab setup for a while. Although it changes frequently at present itâ€™s as below. I will add some pics when I have tidied up the lab/cables My primary lab storage is all contained within an HP Gen8 Microserver. Currently Configured: 1x INTEL Core i3-4130 running atâ€¦\n\n  * [Homelab](https://jameskilby.co.uk/category/homelab/) | [Veeam](https://jameskilby.co.uk/category/veeam/) | [VMware](https://jameskilby.co.uk/category/vmware/)\n\n### [Lab Update â€“ Desired Workloads](https://jameskilby.co.uk/2022/01/lab-update-part-5-desired-workloads/)\n\nBy[James](https://jameskilby.co.uk) January 6, 2022November 11, 2023\n\nMy lab is always undergoing change. Partially as I want to try new things or new ways of doing things. Sometimes because I break things (not always by accident) sometimes itâ€™s a great way to learnâ€¦. I decided to list the workloads I am looking to run (some of these are already in place) Infrastuctureâ€¦\n\n  * [ ](https://jameskilby.co.uk/2022/01/lab-update-part-1-compute/)\n\n[Homelab](https://jameskilby.co.uk/category/homelab/) | [VMware](https://jameskilby.co.uk/category/vmware/)\n\n### [Lab Update â€“ Compute](https://jameskilby.co.uk/2022/01/lab-update-part-1-compute/)\n\nBy[James](https://jameskilby.co.uk) January 6, 2022July 10, 2024\n\nQuite a few changes have happened in the lab recently. so I decided to do a multipart blog on the changes. The refresh was triggered by the purchase of a SuperMicro Server (2027TR-H71FRF) chassis with 4x X9DRT Nodes / Blades. This is known as a BigTwin configuration in SuperMicro parlance. This is something I wasâ€¦\n\n  * [ ![VMC Host Errors](https://jameskilby.co.uk/wp-content/uploads/2022/11/iu-1-768x395.png) ](https://jameskilby.co.uk/2020/09/vmc-host-errors/)\n\n[VMware](https://jameskilby.co.uk/category/vmware/) | [VMware Cloud on AWS](https://jameskilby.co.uk/category/vmware/vmware-cloud-on-aws/)\n\n### [VMC Host Errors](https://jameskilby.co.uk/2020/09/vmc-host-errors/)\n\nBy[James](https://jameskilby.co.uk) September 15, 2020October 1, 2025\n\nWhen you run a large enough Infrastructure failure is inevitable. How you handle that can be a big differentiator. With VMware Cloud on AWS, the hosts are monitored 24Ã—7 by VMware/AWS Support all as part of the service. If you pay for X number of hosts you should have X. That includes during maintenance andâ€¦",
  "excerpt": "![](https://jameskilby.co.uk/wp-content/uploads/2023/11/OrigionalPoweredByvSAN-550x324-1.jpg)\n\n[VMware](https://jameskilby.co.uk/category/vmware/) | [VMware Cloud on AWS](https://jameskilby.co.uk/category/vmware/vmware-cloud-on-aws/) | [vSAN](https://jameskilby.co.uk/category/vmware/vsan-vmware/)\n\n#..."
}